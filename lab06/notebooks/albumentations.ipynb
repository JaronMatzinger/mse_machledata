{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation by Albumentation\n",
    "\n",
    "The core tenet of data centric machine learning is prioritizing high-quality, diverse, and relevant data for training models, recognizing its crucial role in model performance and generalization.\n",
    "\n",
    "One technique that can help you with this is _augmentation_. Augmentation is the process of expanding a dataset by applying transformations like rotation, scaling, or noise to the data. This can help increase diversity in datasets, which in turn helps with generalization.\n",
    "\n",
    "Augmentation is frequently associated with image data, but not exclusive to it. For instance, chemical applications of ML, augmentations such as conformer generation (different spatial arrangements of atoms in molecules) are used frequently. We will stick to images today.\n",
    "\n",
    "At a first glance, augmentation looks very simple. It's really just a few basic transformations on an image. However, there are many pitfalls once masks, labels, boxes etc. get involved. This is why you're better off to use a dedicated augmentation library instead of building your own augmentations from scratch. One such library is [Albumentations](https://albumentations.ai).\n",
    "\n",
    "In their own words,\n",
    "\n",
    "> Albumentations is a fast and flexible image augmentation library. The library is widely used in industry, deep learning research, machine learning competitions, and open source projects. Albumentations is written in Python, and it is licensed under the MIT license. The source code is available at <https://github.com/albumentations-team/albumentations>.\n",
    "\n",
    "You can install `albumentations` from `pip` like any regular python package. We've already taken care of this in the conda environment.\n",
    "\n",
    "## Import the required libraries\n",
    "\n",
    "To start our augmentation adventure, we of course need the `albumentations` library. On top of this, we also require a library to read images from the disk. Here, we'll use [`pillow`](https://pillow.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install albumentations pillow\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation pipelines\n",
    "\n",
    "Albumentations is built around the concept of an \"augmentation pipeline\". If you have ever worked with [PyTorch transforms](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html) or [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html), the syntax should remind you of something.\n",
    "\n",
    "To define an augmentation pipeline, you need to create an instance of the `Compose` class. `Compose` takes a list of transformations (or \"augmentations\") to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=256, height=256),  #Â randomly crop the image to 256x256\n",
    "    A.HorizontalFlip(p=0.5), # horizontally flip 50% of the images\n",
    "    A.RandomBrightnessContrast(p=0.2), # randomly adjust brightness and contrast in 20% of the images\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline performs three augmentations. It randomly crops the image to 256x256, flips 50% of the images horizontally, and randomly changes brightness and contrast in 20% of the images. You can find a list of all available augmentations [in the docs](https://albumentations.ai/docs/api_reference/augmentations/).\n",
    "\n",
    "The parameters of the individual augmentations depend on the type of augmentation, but there is a recurring one: `p`. `p` is a special parameter that is supported by almost all augmentations. It controls the probability of applying the augmentation. `p=0.3` indicates a 30% probability of applying the augmentation.\n",
    "\n",
    "Here is a visualized version of the augmentation pipeline, curtesy of the [albumentations documentation](https://albumentations.ai/docs/getting_started/image_augmentation/#step-2-define-an-augmentation-pipeline).\n",
    "\n",
    "![image.png](../imgs/augmentation_pipeline_visualized.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform images\n",
    "\n",
    "Once you have created you augmentation pipeline, all that remains is reading and transforming your images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the image with PIL\n",
    "image = np.array(Image.open(\"../imgs/cat.jpg\"))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, transforming it is just as easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = transform(image=image)\n",
    "transformed_image = transformed[\"image\"]\n",
    "plt.imshow(transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it!\n",
    "\n",
    "Here are a few more examples you can look at if you want to learn more about albumentations:\n",
    "\n",
    "- [Defining a simple augmentation pipeline for image augmentation](https://albumentations.ai/docs/examples/example/)\n",
    "- [Weather augmentations in Albumentations](https://albumentations.ai/docs/examples/example_weather_transforms/)\n",
    "- [Cool augmentation examples on a diverse set of images from various real-world tasks](https://albumentations.ai/docs/examples/showcase/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation at scale\n",
    "\n",
    "When working with large amounts of data, you'll want to persist the augmentations and not compute them on the fly, every time you use the dataset.\n",
    "In the last section on Albumentations, we will combine augmentation with what we have learnt about data versioning in the previous part.\n",
    "\n",
    "Below you find a simple python script to run Albumentations from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../apply_augmentation.py\n",
    "import os\n",
    "import argparse\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def apply_augmentation(image_path, save_dir, augmentation):\n",
    "    image = Image.open(image_path)\n",
    "    augmented = augmentation(image=np.array(image))\n",
    "    augmented_image = Image.fromarray(augmented['image'])\n",
    "    image_name = os.path.basename(image_path)\n",
    "    augmented_image.save(os.path.join(save_dir, image_name))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    augmentation = getattr(A, args.augmentation)(**args.augmentation_params)\n",
    "\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir)\n",
    "\n",
    "    for filename in os.listdir(args.input_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(args.input_dir, filename)\n",
    "            apply_augmentation(image_path, args.save_dir, augmentation)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Apply Albumentations augmentations to a directory of images.\")\n",
    "    parser.add_argument(\"input_dir\", type=str, help=\"Path to the directory containing input images.\")\n",
    "    parser.add_argument(\"save_dir\", type=str, help=\"Path to the directory to save augmented images.\")\n",
    "    parser.add_argument(\"--augmentation\", type=str, default=\"HorizontalFlip\",\n",
    "                        choices=[name for name in dir(A) if name[0].isupper()],\n",
    "                        help=\"Name of the augmentation class.\")\n",
    "    parser.add_argument(\"--augmentation_params\", type=str, nargs='*', default=[],\n",
    "                        help=\"Parameters for the augmentation in the format key1=value1 key2=value2 ...\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    args.augmentation_params = dict(item.split('=') for item in args.augmentation_params)\n",
    "    args.augmentation_params = {key: float(value) for key, value in args.augmentation_params.items()}\n",
    "\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this script, you can use the command like this:\n",
    "\n",
    "```shell\n",
    "python script.py input_directory output_directory --augmentation AugmentationName --augmentation_params param1=value1 param2=value2 ...\n",
    "```\n",
    "\n",
    "It is a bit limited in as far as it can only apply a single augmentation in each run, but you can of course re-run it on the already augmented data and \"emulate\" `A.Compose` in this way.\n",
    "\n",
    "---\n",
    "\n",
    "## A little bit more on data version control\n",
    "\n",
    "Use the script to augment the `102flowers` data! Here are a few example transformations to get you started.\n",
    "Apply horizontal flip augmentation to images in the \"input_images\" directory and save the augmented images to the \"augmented_images\" directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python apply_augmentation.py input_images augmented_images --augmentation HorizontalFlip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random crop augmentation with width 200 and height 200 to images in the \"input_images\" directory and save the augmented images to the \"augmented_images\" directory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python apply_augmentation.py input_images augmented_images --augmentation RandomCrop --augmentation_params width=200 height=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random brightness and contrast augmentation to images in the \"input_images\" directory and save the augmented images to the \"augmented_images\" directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python apply_augmentation.py input_images augmented_images --augmentation RandomBrightnessContrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most transformations are supported. Don't forget to set the `p` parameter, else you'll override all images. Augmenting all images could take a very long time, feel free to just abort the script at some point.\n",
    "\n",
    "Once you are happy with your augmentations, you can commit the changes using DVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "dvc diff # check what has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this up by the actual commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "dvc commit\n",
    "git add data/102flowers.dvc\n",
    "git commit -m \"Add augmentations to the input images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data version is tied to the `*.dvc` file!\n",
    "\n",
    "When you want to checkout an old version of the data, you first checkout the Git commit that corresponds to this data version (in our case, we can use `HEAD^~1` as this refers to the second most recent commit) and only then checkout the data using `dvc checkout`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-lab-06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
