{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353a8d6",
   "metadata": {
    "tags": [
     "soorgeon-imports"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from exported import mean_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a0fbf",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "upstream = ['load', 'validation']\n",
    "product = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459467f0",
   "metadata": {
    "tags": [
     "soorgeon-unpickle"
    ]
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = pickle.loads(Path(upstream['load']['MODEL_NAME']).read_bytes())\n",
    "rev_df = pickle.loads(Path(upstream['validation']['rev_df']).read_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e83be4",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        0\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f'{MODEL_NAME}')\n",
    "model = AutoModel.from_pretrained(f'{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91dbc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_columns = ['desc_1', 'desc_2', 'desc_3']\n",
    "embeddings = []\n",
    "for desc_col in description_columns:\n",
    "    rev_df[desc_col] = rev_df[desc_col].fillna('')\n",
    "    encoded_input = tokenizer(\n",
    "        rev_df[desc_col].to_list(), padding=True, truncation=True, return_tensors='pt'\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    embeddings.append(mean_pooling(model_output, encoded_input['attention_mask']))\n",
    "stacked_embeddings = torch.hstack(embeddings).numpy()\n",
    "embeddings_reduced = PCA(n_components=0.67).fit_transform(stacked_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f2b04e",
   "metadata": {
    "tags": [
     "soorgeon-pickle"
    ]
   },
   "outputs": [],
   "source": [
    "Path(product['embeddings_reduced']).parent.mkdir(exist_ok=True, parents=True)\n",
    "Path(product['embeddings_reduced']).write_bytes(pickle.dumps(embeddings_reduced))\n",
    "\n",
    "Path(product['rev_df']).parent.mkdir(exist_ok=True, parents=True)\n",
    "Path(product['rev_df']).write_bytes(pickle.dumps(rev_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}