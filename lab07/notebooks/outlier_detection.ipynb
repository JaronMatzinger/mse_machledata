{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection with VAEs\n",
    "\n",
    "In the cell below, you can find the implementation of VAE. For this lab, it is not essential to understand how the model works, but you are, of course, invited to spend some pondering the code. It is based on the implementation described [here](https://hunterheidenreich.com/posts/modern-variational-autoencoder-in-pytorch/) and uses many recent PyTorch features.\n",
    "\n",
    "If you don't want to wait, you can download a (not so good) checkpoint from [here]() and skip all the training-related cells after the model definition. Make sure to set the variables below accordingly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODEL = True  # Set to False if you don't want to train a new VAE.\n",
    "CKPT_PATH = \"\"  #Â Set to path of the checkpoint you downloaded / trained previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder (VAE) class.\n",
    "    \n",
    "    Args:\n",
    "        input_dim (int): Dimensionality of the input data.\n",
    "        hidden_dim (int): Dimensionality of the hidden layer.\n",
    "        latent_dim (int): Dimensionality of the latent space.\n",
    "    \"\"\"\n",
    "\n",
    "    @dataclass\n",
    "    class VAEOutput:\n",
    "        \"\"\"\n",
    "        Dataclass for VAE output.\n",
    "        \n",
    "        Attributes:\n",
    "            z_dist (torch.distributions.Distribution): The distribution of the latent variable z.\n",
    "            z_sample (torch.Tensor): The sampled value of the latent variable z.\n",
    "            x_recon (torch.Tensor): The reconstructed output from the VAE.\n",
    "            loss (torch.Tensor): The overall loss of the VAE.\n",
    "            loss_recon (torch.Tensor): The reconstruction loss component of the VAE loss.\n",
    "            loss_kl (torch.Tensor): The KL divergence component of the VAE loss.\n",
    "        \"\"\"\n",
    "        z_dist: torch.distributions.Distribution\n",
    "        z_sample: torch.Tensor\n",
    "        x_recon: torch.Tensor\n",
    "        \n",
    "        loss: torch.Tensor\n",
    "        loss_recon: torch.Tensor\n",
    "        loss_kl: torch.Tensor\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "                \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 8),\n",
    "            nn.SiLU(), \n",
    "            nn.Linear(hidden_dim // 8, 2 * latent_dim), # 2 for mean and variance.\n",
    "        )\n",
    "        self.softplus = nn.Softplus()\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 8),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 8, hidden_dim // 4),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 4, hidden_dim // 2),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.SiLU(),  # Swish activation function\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, eps: float = 1e-8):\n",
    "        \"\"\"\n",
    "        Encodes the input data into the latent space.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            eps (float): Small value to avoid numerical instability.\n",
    "        \n",
    "        Returns:\n",
    "            torch.distributions.MultivariateNormal: Normal distribution of the encoded data.\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(x, 2, dim=-1)\n",
    "        scale = self.softplus(logvar) + eps\n",
    "        scale_tril = torch.diag_embed(scale)\n",
    "        \n",
    "        return torch.distributions.MultivariateNormal(mu, scale_tril=scale_tril)\n",
    "        \n",
    "    def reparameterize(self, dist):\n",
    "        \"\"\"\n",
    "        Reparameterizes the encoded data to sample from the latent space.\n",
    "        \n",
    "        Args:\n",
    "            dist (torch.distributions.MultivariateNormal): Normal distribution of the encoded data.\n",
    "        Returns:\n",
    "            torch.Tensor: Sampled data from the latent space.\n",
    "        \"\"\"\n",
    "        return dist.rsample()\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decodes the data from the latent space to the original input space.\n",
    "        \n",
    "        Args:\n",
    "            z (torch.Tensor): Data in the latent space.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Reconstructed data in the original input space.\n",
    "        \"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x, compute_loss: bool = True):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the VAE.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input data.\n",
    "            compute_loss (bool): Whether to compute the loss or not.\n",
    "        \n",
    "        Returns:\n",
    "            VAEOutput: VAE output dataclass.\n",
    "        \"\"\"\n",
    "        dist = self.encode(x)\n",
    "        z = self.reparameterize(dist)\n",
    "        recon_x = self.decode(z)\n",
    "        \n",
    "        if not compute_loss:\n",
    "            return VAE.VAEOutput(\n",
    "                z_dist=dist,\n",
    "                z_sample=z,\n",
    "                x_recon=recon_x,\n",
    "                loss=None,\n",
    "                loss_recon=None,\n",
    "                loss_kl=None,\n",
    "            )\n",
    "        \n",
    "        # compute loss terms \n",
    "        loss_recon = F.binary_cross_entropy(recon_x, x + 0.5, reduction='none').sum(-1).mean()\n",
    "        std_normal = torch.distributions.MultivariateNormal(\n",
    "            torch.zeros_like(z, device=z.device),\n",
    "            scale_tril=torch.eye(z.shape[-1], device=z.device).unsqueeze(0).expand(z.shape[0], -1, -1),\n",
    "        )\n",
    "        loss_kl = torch.distributions.kl.kl_divergence(dist, std_normal).mean()\n",
    "                \n",
    "        loss = loss_recon + loss_kl\n",
    "        \n",
    "        return VAE.VAEOutput(\n",
    "            z_dist=dist,\n",
    "            z_sample=z,\n",
    "            x_recon=recon_x,\n",
    "            loss=loss,\n",
    "            loss_recon=loss_recon,\n",
    "            loss_kl=loss_kl,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell just prepares the data. Nothing you haven't seen before, but make sure to execute it, even if you don't want to train the model. We need the data later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Lambda(lambda x: x.view(-1) - 0.5),\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "train_data = datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=True, \n",
    "    transform=transform,\n",
    ")\n",
    "# Download and load the test data\n",
    "test_data = datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=False, \n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VAE(input_dim=784, hidden_dim=512, latent_dim=16).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next three cells define training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, optimizer, prev_updates):\n",
    "    \"\"\"\n",
    "    Trains the model on the given data.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to train.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "        loss_fn: The loss function.\n",
    "        optimizer: The optimizer.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        n_upd = prev_updates + batch_idx\n",
    "        \n",
    "        data = data.view(data.size(0), -1)  # Flatten the data\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        output = model(data)  # Forward pass\n",
    "        loss = output.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if n_upd % 100 == 0:\n",
    "            # Calculate and log gradient norms\n",
    "            total_norm = 0.0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** (1. / 2)\n",
    "        \n",
    "            print(f'Step {n_upd:,} (N samples: {n_upd*batch_size:,}), Loss: {loss.item():.4f} (Recon: {output.loss_recon.item():.4f}, KL: {output.loss_kl.item():.4f}) Grad: {total_norm:.4f}')\n",
    "            \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)    \n",
    "        \n",
    "        optimizer.step()  # Update the model parameters\n",
    "        \n",
    "    return prev_updates + len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    \"\"\"\n",
    "    Tests the model on the given data.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model to test.\n",
    "        dataloader (torch.utils.data.DataLoader): The data loader.\n",
    "        cur_step (int): The current step.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    test_recon_loss = 0\n",
    "    test_kl_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(dataloader, desc='Testing'):\n",
    "            data = data.to(device)\n",
    "            data = data.view(data.size(0), -1)  # Flatten the data\n",
    "            \n",
    "            output = model(data, compute_loss=True)  # Forward pass\n",
    "            \n",
    "            test_loss += output.loss.item()\n",
    "            test_recon_loss += output.loss_recon.item()\n",
    "            test_kl_loss += output.loss_kl.item()\n",
    "            \n",
    "    test_loss /= len(dataloader)\n",
    "    test_recon_loss /= len(dataloader)\n",
    "    test_kl_loss /= len(dataloader)\n",
    "    print(f'====> Test set loss: {test_loss:.4f} (BCE: {test_recon_loss:.4f}, KLD: {test_kl_loss:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you set the `TRAIN_MODEL` and `CKPT_PATH` variables correctly, depending on whether you want to train a new model or not, then execute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        prev_updates = train(model, train_loader, optimizer, prev_updates)\n",
    "        test(model, test_loader)\n",
    "        torch.save(model.state_dict(), 'outlier_vae.pth')\n",
    "else:\n",
    "    model.load_state_dict(torch.load(CKPT_PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate that our model works, let's quickly validate the reconstructions by visual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Select a random batch of images from the test dataset\n",
    "data, _ = next(iter(test_loader))\n",
    "data = data.to(device)\n",
    "\n",
    "# Generate reconstructions\n",
    "with torch.no_grad():\n",
    "    output = model(data, compute_loss=False)\n",
    "    reconstructions = output.x_recon.cpu().numpy()\n",
    "\n",
    "# Plot the original images and their reconstructions\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(20, 4))\n",
    "\n",
    "for i in range(10):\n",
    "    # Plot original image\n",
    "    axes[0, i].imshow(data[i].view(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot reconstructed image\n",
    "    axes[1, i].imshow(reconstructions[i].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's shift our attention to the topic for which we are actually here: Detecting outliers.\n",
    "As mentioned in the introduction, we are trying to detect outliers by checking how well the input data can be reconstructed.\n",
    "For this, we have to set a threshold, above which we declare a sample an _outlier_. We will take care of this later, for now, just assume we have it already. Finish the implementation of the function in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outlier(vae, x, th):\n",
    "    \"\"\"\n",
    "    vae: The variational autoencoder.\n",
    "    x: The sample we want to compare against training the distribution.\n",
    "    th: The detection threshold.\n",
    "    \"\"\"\n",
    "    #Â TODO: Compute reconstruction loss for x.\n",
    "\n",
    "    #Â TODO: Compare loss against threshold.\n",
    "\n",
    "    #Â TODO: Decide whether x is an outlier or not\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've procrastinated for long enough. Let's find the threshold. Here is our approach:\n",
    "\n",
    "1. Compute the reconstruction loss for (a subset of) the training samples.\n",
    "2. Assume that x% of the data are outliers.\n",
    "3. Set the threshold to the x-th percentile.\n",
    "\n",
    "As you can see, this is not exact science. In reality, the setting of such thresholds is a long process of calibration until you have found a value that is suitable for your use case. As is often the case in statistics, it comes down to balancing \n",
    "\n",
    "Here, let's assume that 1% of all samples are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â TODO: Find the threshold!\n",
    "threshold = 0.0\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(train_loader, desc='Computing threshold'):\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.size(0), -1)  # Flatten the data\n",
    "\n",
    "        output = model(data, compute_loss=True)  # Forward pass\n",
    "        \n",
    "        #Â TODO: Compute the reconstruction loss.\n",
    "        #Â ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now we have everything to detect outliers. To test our model, let's create some distorted samples!\n",
    "For this we'll use alibi-detect, a library that provides a lot of tools for outlier detection and similar tasks. (Yes, we could have used it for the VAE as well, but where's the fun in that?)\n",
    "You can customize the distortion by changing the parameters in the call to [`apply_mask`](https://docs.seldon.io/projects/alibi-detect/en/latest/api/alibi_detect.utils.perturbation.html#alibi_detect.utils.perturbation.apply_mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from alibi_detect.utils.perturbation import apply_mask\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#Â Index of the sample we want to perturb.\n",
    "i = 0\n",
    "\n",
    "# create masked instance\n",
    "x = test_data[i][0].reshape(1, 28, 28, 1)\n",
    "x_perturbed, _ = apply_mask(\n",
    "    x,\n",
    "    mask_size=(8, 8),\n",
    "    n_masks=1,\n",
    "    channels=[0],\n",
    "    mask_type=\"normal\",\n",
    "    noise_distr=(0, 1),\n",
    "    clip_rng=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Plot original x\n",
    "axes[0].imshow(x.reshape(28, 28), cmap='gray')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Original x')\n",
    "\n",
    "# Plot perturbed x\n",
    "axes[1].imshow(x_perturbed.reshape(28, 28), cmap='gray')\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Perturbed x')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these samples, let's test the `detect_outliers` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_outlier(model, x_perturbed, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-lab-07",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
